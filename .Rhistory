plot.new()
map('worldHires','Taiwan')
library(maps)
library(mapdata)
library(maptools)
top30
library(readxl)
X105年舊電費分攤比例表_全 <- read_excel("~/dsR/全校水電瓦斯/105年舊電費分攤比例表 - 全.xlsx")
View(X105年舊電費分攤比例表_全)
dorm_electricity<-X105年舊電費分攤比例表_全[2,]
dorm_electricity
dorm_electricity<-X105年舊電費分攤比例表_全$建物名稱
dorm_electricity<-X105年舊電費分攤比例表_全$建物名稱
dorm_electricity
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位==校總區內學生宿舍
dorm_electricity
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位==校總區內學生宿舍
dorm_electricity
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位=="校總區內學生宿舍"
dorm_electricity
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity<-filter("校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity<-filter(使用單位==校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(使用單位==校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(使用單位=="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(X105年舊電費分攤比例表_全$使用單位=="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(X105年舊電費分攤比例表_全$使用單位 = ="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(X105年舊電費分攤比例表_全$"使用單位" = ="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(X105年舊電費分攤比例表_全$"使用單位" =="校總區內學生宿舍")
library(dypler)
library(dplyr)
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(X105年舊電費分攤比例表_全$"使用單位" =="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(X105年舊電費分攤比例表_全 =="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(X105年舊電費分攤比例表_全=="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
dorm_electricity1<-filter(dorm_electricity=="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
as.vector(dorm_electricity)
dorm_electricity1<-filter(dorm_electricity=="校總區內學生宿舍")
dorm_electricity1<-filter(dorm_electricity,dorm_electricity=="校總區內學生宿舍")
dorm_electricity1<-filter(dorm_electricity, dorm_electricity=="校總區內學生宿舍")
dorm_electricity<-X105年舊電費分攤比例表_全$使用單位
as.vector(dorm_electricity)
dorm_electricity<-X105年舊電費分攤比例表_全$校總區內學生宿舍
as.vector(dorm_electricity)
dorm_electricity<-X105年舊電費分攤比例表_全$"校總區內學生宿舍"
dorm_electricity<-X105年舊電費分攤比例表_全
dorm_electricity[51,]
dorm_electricity[51:69,]
data_frame(dorm_electricity[51:69,])
a<-dorm_electricity[51:69,]
data_frame(a)
install.packages("e1071", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
install.packages("MLmetrics", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(e1071)
library(MLmetrics)
read.table("data.txt",sep="\t", header=T)
read.table("data.txt", header=T)
read.table("doc.rtf", header=T)
feature <- df[, c(8, 10, 11)]
head(feature, 4)
df <- read.table('doc.txt', sep='\t', header=T)
df <- read.table(~/'doc.txt', header=T)
df <- read.table(~desktop/'doc.txt', header=T)
df <- read.table(~dsR/'doc.txt', header=T)
df <- read.table(~dsR/'doc.txt')
df <- read.table(~dsR/"doc.txt")
df <- read.table(~/dsR/"doc.txt")
df <- read.table(~/dsR/"doc.txt")
df <- read.table(~dsR/"doc.txt")
df <- read.table(~dsR/"doc.txt"/)
df <- read.table("~dsR/doc.txt")
df <- read.table("~/dsR/doc.txt")
df <- read.table("~/dsR/doc.txt" sep='\t', header=T)
df <- read.table("~/dsR/doc.txt sep='\t', header=T"")
df <- read.table("~/dsR/doc.txt sep='\t', header=T")
df <- read.table("~/dsR/doc.txt ,sep='\t', header=T")
df <- read.table("~/dsR/doc.txt,sep='\t', header=T")
df <- read.table("~/dsR/doc.txt, sep='\t', header=T")
df <- read.table("~/dsR/doc.txt", sep='\t', header=T)
head(df, 4)
feature <- df[, c(8, 10, 11)]
head(feature, 4)
testset <- feature[testindex,]
index <- 1:nrow(df)
testindex <- sample(index, trunc(length(index)*30/100))
trainset <- feature[-testindex,]
testset <- feature[testindex,]
index <- 1:nrow(df)
testindex <- sample(index, trunc(length(index)*30/100))
index
testindex
testset <- feature[testindex,]
(tuned <- tune.svm(是否為網紅~., data = trainset, cost=10^(-1:2), gamma=c(.5,1,2)))
model <- svm(是否為網紅~., data = trainset, kernel='linear', cost = 1, gamma = 1)
?kernel
prediction <- predict(model, testset[,-3])
prediction
model <- svm(是否為網紅~., data = trainset, kernel='linear', cost = 100, gamma = 2)
prediction <- predict(model, testset[,-3])
prediction
ConfusionMatrix(prediction, testset[,3])
F1_Score(prediction, testset[,3])
factor(df$身價)
money<-factor(df$身價)
levels(money)
m1<-subset(df,subset=df$身價<=50)
m2<-subset(df,subset=df$身價>=100&&df$身價<=500)
m2<-subset(df,subset=df$身價>=1000&&df$身價<=5000)
m2<-subset(df,subset=df$身價>=10000&&df$身價<=20000)
m2<-subset(df,subset=df$身價>=500000)
m2<-subset(df,subset=df$身價>=5000000)
m1<-subset(df,subset=df$身價<=50)
m2<-subset(df,subset=df$身價>=100&&df$身價<=500)
m3<-subset(df,subset=df$身價>=1000&&df$身價<=5000)
m4<-subset(df,subset=df$身價>=10000&&df$身價<=20000)
m5<-subset(df,subset=df$身價>=500000)
m6<-subset(df,subset=df$身價>=5000000)
feature <- df[, c(6,8, 10, 12)]
head(feature, 4)
index <- 1:nrow(df)
index
testindex <- sample(index, trunc(length(index)*30/100))
testindex
trainset <- feature[-testindex,]
testset <- feature[testindex,]
model <- svm(是否為網紅~., data = trainset, kernel='linear', cost = 100, gamma = 2)
model <- svm(是否為網紅~., data = trainset, kernel='linear', cost = 100, gamma = 2)
tuned <- tune.svm(身價~., data = trainset, cost=10^(-1:2), gamma=c(.5,1,2))
tuned
model <- svm(是否為網紅~., data = trainset, kernel='linear', cost = 10, gamma = 0.5)
model <- svm(身價~., data = trainset, kernel='linear', cost = 10, gamma = 0.5)
model
prediction <- predict(model, testset[,-3])
prediction <- predict(model, testset[,-4])
prediction
ConfusionMatrix(prediction, testset[,4])
F1_Score(prediction, testset[,3])
ConfusionMatrix(prediction, testset[,4])
F1_Score(prediction, testset[,4])
ConfusionMatrix(prediction, testset[,4])
tuned
tuned <- tune.svm(身價~., data = trainset, cost=10^(-1:2), gamma=c(.5,1,2))
tuned
model <- svm(身價~., data = trainset, kernel='linear', cost = 10, gamma = 0.5)
model <- svm(身價~., data = trainset, kernel='linear', cost = 1, gamma = 0.5)
model
prediction <- predict(model, testset[,-4])
prediction
ConfusionMatrix(prediction, testset[,4])
prediction
rich<-subset(df,subset=df$身價>=10000)
poor<-subset(df,subset=df$身價<10000)
money<- factor(c("rich","poor"))
money
?cbind
df1<-cbind(df,money)
levels(money)
feature <- df[, c(6,8, 10, 12)]
head(feature, 4)
index <- 1:nrow(df)
index
testindex <- sample(index, trunc(length(index)*30/100))
testindex
trainset <- feature[-testindex,]
testset <- feature[testindex,]
tuned <- tune.svm(身價~., data = trainset, cost=10^(-1:2), gamma=c(.5,1,2))
tuned
model <- svm(身價~., data = trainset, kernel='linear', cost = 10, gamma = 1)
model
prediction <- predict(model, testset[,-4])
prediction
ConfusionMatrix(prediction, testset[,4])
F1_Score(prediction, testset[,4])
ConfusionMatrix(prediction, testset[,4])
library(janeaustenr)
library(tidyverse)
library(tidytext)
tidy_books <- austen_books() %>%
unnest_tokens(word, text) %>% # convert sentence to token
group_by(book,word) %>%
mutate(freq = n()) %>% # calculate term count
arrange(desc(freq)) %>%
ungroup()
view(tdm)
View(tdm)
tidy_books <- austen_books() %>%
unnest_tokens(word, text) %>% # convert sentence to token
group_by(book,word) %>%
mutate(freq = n()) %>% # calculate term count
arrange(desc(freq)) %>%
ungroup()
tidy_books<- tidy_books %>% # remove stopwords
anti_join(stop_words)
length(unique(tidy_books$word))
tidy_books <- tidy_books %>% # calculate total term count
group_by(word) %>%
mutate(total = n()) %>%
ungroup() #%>%
filter(total >= 10) # remove rare words
length(unique(tidy_books$word))
tdm <- table(tidy_books$book,tidy_books$word) %>%
as.data.frame.matrix() # build term-document matrix
View(tdm)
library("jiebaR")
df <- read_csv("dsR/comments_prep.csv")
stopchi <- as.data.frame(read_lines('dsR/stopword.txt',skip = 1))
names(stopchi)<-'word'
# kmeans clustering using iris data
#https://dotblogs.com.tw/dragon229/2013/02/04/89919
df <- read_csv("dsR/comments_prep.csv")
df <- read_csv("~/dsR/comments_prep.csv")
stopchi <- as.data.frame(read_lines('~/dsR/stopword.txt',skip = 1))
names(stopchi)<-'word'
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
tidy_books <- austen_books() %>%
unnest_tokens(word, text) %>% # convert sentence to token
group_by(book,word) %>%
mutate(freq = n()) %>% # calculate term count
arrange(desc(freq)) %>%
ungroup()
tidy_books
View(tidy_books)
tidy_books<- tidy_books %>% # remove stopwords
anti_join(stop_words)
tidy_books <- austen_books() %>%
unnest_tokens(word, text) %>% # convert sentence to token
group_by(book,word) %>%
mutate(freq = n()) %>% # calculate term count
arrange(desc(freq)) %>%
ungroup()
tidy_books<- tidy_books %>% # remove stopwords
anti_join(stop_words)
tidy_books<- tidy_books %>% # remove stopwords
anti_join(stop_word)
View(stop_words)
tidy_books<- tidy_books %>% # remove stopwords
anti_join(stop_words)
length(unique(tidy_books$word))
tidy_books <- tidy_books %>% # calculate total term count
group_by(word) %>%
mutate(total = n()) %>%
ungroup() #%>%
View(tidy_books)
length(unique(tidy_books$word))
View(tidy_books)
length(unique(tidy_books$word))
tidy_books <- tidy_books %>% # calculate total term count
group_by(word) %>%
mutate(total = n()) %>%
ungroup() #%>%
length(unique(tidy_books$word))
filter(total >= 10) # remove rare words
tidy_books <- tidy_books %>% # calculate total term count
group_by(word) %>%
mutate(total = n()) %>%
ungroup() #%>%
length(unique(tidy_books$word))
tidy_books <- tidy_books %>% # calculate total term count
group_by(word) %>%
mutate(total = n()) %>%
ungroup() #%>%
filter(total >= 10) # remove rare words
length(unique(tidy_books$word))
tidy_books<- tidy_books %>% # remove stopwords
anti_join(stop_words)     #有一樣會踢除掉
length(unique(tidy_books$word))
tidy_books <- tidy_books %>% # calculate total term count
group_by(word) %>%
mutate(total = n()) %>%
ungroup() #%>%
filter(total >= 10) # remove rare words
filter(total >= 10)
filter( total >= 10)   # remove rare words
tidy_books <- tidy_books %>% # calculate total term count
group_by(word) %>%
mutate(total = n()) %>%
ungroup() #%>%
filter( total >= 10)   # remove rare words
tdm <- table(tidy_books$book,tidy_books$word) %>%
as.data.frame.matrix() # build term-document matrix
View(tdm)
filter(total >＝ 10)   # remove rare words
filter(total >= 10)   # remove rare words
filter(total >= 10)   # remove rare words
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
set.seed(20) # set random seed to ensure reproducibility
irisCluster <- kmeans(iris[, 3:4], centers=3, nstart=20) # run kmeans model
irisCluster$cluster
irisCluster$cluster <- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster))
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
log.iris <- log(iris[, 1:4]) # feature column
iris.species <- iris[, 5] # target column
iris.pca <- prcomp(log.iris,
center = TRUE, # standarization
scale. = TRUE)
rotated <- iris.pca$x %>% # data projected in pca space
as.data.frame()
ggplot(rotated, aes(PC1, PC2, color = iris$Species)) + geom_point()
PCACluster <- kmeans(rotated[, 1:2], 3, nstart = 20) # run kmeans model
PCACluster$cluster <- as.factor(PCACluster$cluster)
ggplot(rotated, aes(PC1, PC2, color = PCACluster$cluster)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
log.iris <- log(iris[, 1:4]) # feature column
iris.species <- iris[, 5] # target column
iris.pca <- prcomp(log.iris,
center = TRUE, # standarization
scale. = TRUE)
rotated <- iris.pca$x %>% # data projected in pca space
as.data.frame()
ggplot(rotated, aes(PC1, PC2, color = iris$Species)) + geom_point()
PCACluster <- kmeans(rotated[, 1:2], 3, nstart = 20) # run kmeans model
PCACluster$cluster <- as.factor(PCACluster$cluster)
ggplot(rotated, aes(PC1, PC2, color = PCACluster$cluster)) + geom_point()
read.csv("~/dsR/comments_prep.csv")
library("jiebaR")
df <- read_csv("~/dsR/comments_prep.csv")
stopchi <- as.data.frame(read_lines('~/dsR/stopword.txt',skip = 1))
names(stopchi)<-'word'
library(tidytext)
cutter = worker()
a<-cutter(df)
library("jiebaR")
cutter = worker()
a<-cutter(df)
a<-cutter[df]
library(rattle)
summary(weather)
install.packages(rattle)
install.packages("rattle", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
install.packages("rpart")
library(rattle)
library(rattle)
install.packages("rattle", repos="http://rattle.togaware.com")
install.packages("rattle", repos = "http://rattle.togaware.com")
install.packages("weather")
summary(weather)
summary(weather)
library(rattle)
require(weather)
library(rattle)
require(weather)
install.packages("weather")
require(weather)
summary(weather)
library(rpart)
weather2 <- subset(weather, select=-c(RISK_MM))
model <- rpart(formula=RainTomorrow ~ ., data=weather2, method="class")
summary(model)
library(rattle)
rattle()
install.packages("rattle", repos="http://rattle.togaware.com")
install.packages("rattle", repos = "http://rattle.togaware.com")
install.packages("rattle", repos="http://rattle.togaware.com")
install.packages("rattle", repos = "http://rattle.togaware.com")
library(rattle)
library("rpart", lib.loc="~/Library/R/3.3/library")
rattle()
install.packages("rattle", repos="http://rattle.togaware.com")
install.packages("rattle", repos = "http://rattle.togaware.com")
library(rattle)
rattle()
install.packages("RGtk2")
install.packages("RGtk2")
library(rattle)
rattle()
write.csv(weather, file="weather.csv")
library(rattle)
rattle()
require("RGtk2")
install.packages("RGtk2")
install.packages("RGtk2")
require(RGtk2)
install.packages("rattle", repos="http://rattle.togaware.com")
library(rattle)
rattle()
rattle()
require(RGtk2)
library(rattle)
rattle()
detach("package:RGtk2", unload=TRUE)
remove.packages("RGtk2", lib="~/Library/R/3.3/library")
rattle()
a<-read.csv("~/dsR/data/ALLYEAR")
a<-read.table("~/dsR/data/ALLYEAR")
a<-read.table("~/dsR/data/ALLYEAR.xlsx")
a<-read.csv("~/dsR/data/ALLYEAR.xlsx")
a<-read.csv("~/dsR/ALLYEAR.xlsx")
a<-read.table("~/dsR/ALLYEAR.xlsx")
a<-read.table("~/dsR/ALLYEAR.csv")
View(a)
a<-read.csv("~/dsR/ALLYEAR.csv")
a<-read.csv("~/dsR/ALLYEAR")
a<-read.csv("~/dsR/ALLYEAR")
a<-read.csv("~/dsR/ALLYEAR", header=T)
a<-read.csv("~/dsR/ALLYEAR", header=T,encoding = "Big5")
a<-read.csv("~/dsR/ALLYEAR.csv", header=T,encoding = "Big5")
a<-read.csv("~/dsR/ALLYEAR.csv, header=T,encoding = "Big5"")
a<-read.csv("~/dsR/ALLYEAR.csv, header=T")
a<-read.csv("~/dsR/ALLYEAR, header=T")
a<-read.table("~/dsR/ALLYEAR, header=T")
a<-read.table("~/dsR/ALLYEAR")
a<-read.csv("~/dsR/ALLYEAR")
a<-read.csv("~/dsR/ALLYEAR")
a<-read.csv("~/dsR/ALLYEAR.csv")
a<-read.csv(~/dsR/"ALLYEAR.csv")
library(readr)
ALLYEAR <- read_csv("~/dsR/data/ALLYEAR.csv")
View(ALLYEAR)
a<-read.csv("~/dsR/ALLYEAR")
a<-read.csv("~/dsR/ALLYEAR", header = T)
a<-read.csv("~/dsR/ALLYEAR.csv")
read.csv("~/dsR/comments_prep.csv")
a<-read.csv("~/dsR/allyear.csv")
read.csv("~/dsR/allyear.csv")
read.csv("~/dsR/data/allyear.csv")
read.csv("~/dsR/data/allyear")
read.csv("~/dsR/data/allyear.csv")
library(readxl)
ALLYEAR <- read_excel("~/dsR/data/ALLYEAR.xlsx")
View(ALLYEAR)
ALLYEAR$`10312用電(度)`
ALLYEAR$`10312用電(度)`[9,]
ALLYEAR$`10312用電(度)`[9]
ALLYEAR$`10312用電(度)`[9]
ALLYEAR$`10401用電(度)`[9]
ALLYEAR$`10402用電(度)`[9]
ALLYEAR$`10411用電(度)`[9]
library(ggplot2)
library(qplot)
win1<-ALLYEAR$`10312用電(度)`[9]
win2<-ALLYEAR$`10401用電(度)`[9]
win3<-ALLYEAR$`10402用電(度)`[9]
win4<-ALLYEAR$`10411用電(度)`[9]
qplot(win1,win2,win3,win4)
install.packages(qplot)
install.packages("qplot"")
install.packages("qplot")
install.packages("qplot")
library(qplot)
ggplot(data=ALLYEAR, win1)
sum(win1+win2+win3+win4)
a<-sum(win1+win2+win3+win4)
ggplot(data=ALLYEAR, a)+
geom_line(aes(x="冬季",
y="用電量", )
ggplot(data=ALLYEAR, a)+
ggplot(a)+
geom_line(aes(x="冬季",
y="用電量", )
ggplot(a)+
data.frame(ALLYEAR)
ALLYEAR[9]$`10403用電(度)`
ALLYEAR[9]
ALLYEAR[9,]
ALLYEAR[9,]$`10403用電(度)`
ALLYEAR[9,]$`10403用電(度)`
ALLYEAR[9,]$`10404用電(度)`
ALLYEAR[9,]$`10405用電(度)`
ALLYEAR[9,]$`10406用電(度)`
spr1<-ALLYEAR[9,]$`10403用電(度)`
spr2<-ALLYEAR[9,]$`10404用電(度)`
spr3<-ALLYEAR[9,]$`10405用電(度)`
spr4<-ALLYEAR[9,]$`10406用電(度)`
sum(spr1+spr2+spr3+spr4)
b<-sum(spr1+spr2+spr3+spr4)
spr1<-ALLYEAR[9,21:24]
spr1
spr<-ALLYEAR[9,21:24]
spr
spr104G<-ALLYEAR[9,21:24]
spr103G<-ALLYEAR[112,21:24]
plot(spr103G,spr104G)
spr104G<-ALLYEAR[9,21:24]
spr103G<-ALLYEAR[112,21:24]
spr103G
sum(spr103G)
spr104G
spr104G<-rbind(spr103G)
spr104G
spr104G<-cbind(spr103G)
spr104G
spr104G<-ALLYEAR[9,21:24]
spr103G<-ALLYEAR[112,21:24]
spr104G<-cbind(spr103G)
spr104G
spr104G<-ALLYEAR[9&112,21:24]
spr104G
spr104G<-ALLYEAR[9&112,21:24]
spr103G<-ALLYEAR[112,21:24]
spr104G
